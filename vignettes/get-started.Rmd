---
title: "get-started"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{get-started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_chunk$set(echo = TRUE)
```

# Rforce

**Composite Endpoint** data type that has gained momentum in the field, due to its fully consideration on the all observated events for each patients, in comparison to the **Competing Risk** setting that utilize only on the first observed event for each patient. 

A parametric approach, like **Wcompo**[@mao2016semiparametric], has proposed to addressed the inference challenge while imposing the proportional hazard assumption. Inspired by **Random Survival Forest** [@Ishwaran2008] and **Counting Process Information Unit(CPIU)** [@wongvibulsin_clinical_2019], we here porposed a non-parametric ensememble method, <u>*Random Froest for Composite Endpoints*(**Rforce**)</u>, to further relax the proportional hazard assumption. 

Below, we like to demonstrate a simulated data example to show off the simplistic pipeline of **Rforce**.

## Generating Composite Endpoint Data

* `Rforce` package provides functions to generate composite endpoints survival data with options
  * Constant baseline hazard
  * Non-constant() baseline hazard
  * Proportional hazard
  * Non-proportional hazard
  * see details for these options in `Articles/Generating Composite Endpoints/Survival Data`

* By default, we generate a non-constant(Weibull) baseline hazard with proportional hazard assumption.
```{r}
library(Rforce)
library(dplyr)
data_list <- compo_sim(n_patients = 500, verbose = FALSE)
data_list$true_beta
data_list$hazard_function
head(data_list$dataset)
```

* Each patient's observation can span across multiple rows, each row representing one of event of interest, ordered by time of occurrence.
* For completeness, each patient has complete observations up to terminal(fatal) event.
* However, `compo_sim()` only generates non time-varying covariates although the proposed methodology can handle time-varying covariates.
* Here, we generate 6 binary covariates and 4 continuous covariates by default.
* The hazard function consist of baseline hazard $\lambda_0(t)$ and parametric part $g(\mathbf{Z})$, i.e.,
  \[\lambda(t) = \lambda_0(t) g(\mathbf{Z})\]
  where $\lambda_0(t) \sim Weibull(1, 1)$ and $g(\mathbf{Z}) = \exp(\beta \mathbf{Z})$. 
* Only two covariates have non-zero effects on the hazard function, $\beta$ is indicated by `data_list$true_beta`.

## Implementating Random Censoring
* In real world clinical trials, patients may be censored before experiencing terminal event.
* `Rforce` package provides `random_censoring()` function to implement random censoring mechanism on the generated complete data.

```{r}
df <- random_censoring(
  data = data_list$dataset,
  event_rate = 0.5
)
head(df)
```

## Step 1: Converting CPIU-wide Format

* Evidently, the hazard function $\lambda(t)$ is not a constant of time. Inspired by **Counting Process Information Unit(CPIU)**, we convert the observed data into <u>CPIU-wide</u> format to better capture the hazard pattern for the population.
* The interval of units `units_of_cpiu` is defined such that each interval contains approximately equal number of events, e.g. 10 intervals. 
* `patients_to_cpius()` is customized for these purpose.

```{r}
n_intervals <- 10
probs <- seq(0, 1, length.out = n_intervals + 1)
observed_times <- df %>% dplyr::pull(X)
break_points <- stats::quantile(
  observed_times,
  probs = probs,
  na.rm = TRUE
)
break_points[1] <- 0.0 # ensure starting at 0
break_points[n_intervals + 1] <- max(observed_times, na.rm = TRUE) * 1.001 # ensure ending at max time
units_of_cpius <- diff(break_points)
cpiu_wide <- patients_to_cpius(
  data_to_convert = df,
  units_of_cpiu = units_of_cpiu
)
names(cpiu_wide)
class(cpiu_wide)
```

* `CPIU` is S3 class defined in **Rforce** package to better encapsulate `CPIU-wide` formatted data, along with the metadata.
* Two main `data.frame`'s are included, 
  * `designMatrix_Y`: covariates + number of events in each defined interval
  * `auxilaryFeatures`: `Id` + `pseudo risk time` in each defined interval + `X` + `Status`


## Step 2: Encoding Factor/Categorical Variables
  
* In real world, there may have factor or categorical variable in the data. Internally, **Rforce** encodes those variables into dummy variables, to avoid the collinearlity, the number of encoded dummy varaibles for each categorical `variable` always equal to `nlevels(variable) - 1`.

* Worthy to metion, **Rforce** don't evaluate the variable importance on individual levels of these categorical variable. Through the carefully design permutation framework, **Rforce** direct output the variable importance on the variable itself after the model fitting.
  
* By default, all the columns in `designMatrix_Y` will be used in dummy encoding and random forest fitting; One can customize the original columns to be considered by modifying the parameter `cols_to_keep`.
  
```{r}
cpiu_wide <- cpius_to_dummy(cpiu_wide, cols_to_keep = NULL)
```

## Step 3: Fit Random Forest Model

* `Rforce()` does the final model fitting
* Internally, there are various of settings for the hyperparameters for growing random forest with some smart default. For example, 
  * `n_trees`
  * `mtry`
  * `n_splits`
  * `min_gain`
  * `min_node_size`
  * `max_depth`
  * `seed`.
  * see details for the default in `Reference/Rforce()`.
* Same time, the default `split_rule` is using the proposed quasi-likelihood ratio `Rforce-QLR`, it is more computational efficient than other two proposed rules, 
  * `Rforce-GEE`
  * `Rforce-GEEInter`
  * see details for the default in `Reference/Rforce()`.

```{r}
fit <- Rforce(
  cpius = cpiu_wide,
  split_rule = "Rforce-QLR"
)
```


## 3-in-1 Equivalent Command

* `Rforce` is also a bigger wrapper function for `Step 1 - 3`
  
```{r}
fit <- Rforce(
  data = df,
  formula = Surv(Id, X, Status) ~ ., 
  n_intervals = 10,
  split_rule = "Rforce-QLR"
)
```

## Reference